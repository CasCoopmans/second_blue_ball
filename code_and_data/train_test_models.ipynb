{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, dot, multiply, Lambda\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from random import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from datetime import datetime\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate linear train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size_of_training in range(100,1100,100):\n",
    "    \n",
    "    for simulations in range(1):\n",
    "        K.clear_session()\n",
    "        print('simulation number: ', simulations+1)\n",
    "        lincorrect = 0\n",
    "        absencecorrect = 0\n",
    "        countabsent = 0\n",
    "        \n",
    "        l_input_data_train, l_output_data_train, l_input_data_test, l_output_data_test = gen_lin(train_size=size_of_training)\n",
    "\n",
    "        # define class weights\n",
    "        y_int = [y.argmax() for y in l_output_data_train]\n",
    "        class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "        class_weights = {0: 0, 1: class_weights[0], 2: class_weights[1], 3: class_weights[2], \n",
    "             4: class_weights[3], 5: class_weights[4], 6: class_weights[5], 7: 0, 8: class_weights[6]}\n",
    "\n",
    "        vec_in = Input(shape=(4, 57), dtype='float32', name='vec_in')\n",
    "        lstm = LSTM(100, return_sequences=False, name='lstm')(vec_in)\n",
    "        target_pos = Dense(9, name='target_pos', activation='softmax')(lstm)\n",
    "        model = Model(inputs=vec_in,outputs=target_pos)\n",
    "        model.summary()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(l_input_data_train,l_output_data_train, steps_per_epoch=100, epochs=50,verbose=1,class_weight=class_weights)\n",
    "\n",
    "        eval_model = model.evaluate(x = l_input_data_test, y = l_output_data_test, verbose = 1) \n",
    "        loss = eval_model[0]\n",
    "        accuracy = eval_model[1]\n",
    "\n",
    "        predictions = model.predict(l_input_data_test)\n",
    "        for testtrials in range(len(predictions)):\n",
    "            index_prediction = list(predictions[testtrials]).index(max(predictions[testtrials]))+1\n",
    "            index_answer = list(l_output_data_test[testtrials]).index(max(l_output_data_test[testtrials]))+1\n",
    "\n",
    "            if index_answer == 9:\n",
    "                countabsent += 1\n",
    "\n",
    "            if index_prediction == index_answer:\n",
    "                if index_answer == 9:\n",
    "                    absencecorrect += 1\n",
    "                else:\n",
    "                    lincorrect += 1\n",
    "                    \n",
    "        abscor_percent = absencecorrect/countabsent*100\n",
    "        lincor_percent = lincorrect/(100-countabsent)*100\n",
    "\n",
    "        if simulations == 0:\n",
    "            evaluation = pd.DataFrame([[simulations+1, loss,accuracy,absencecorrect,abscor_percent,lincorrect,lincor_percent, size_of_training]], \n",
    "                                       columns=('run', 'loss', 'accuracy', 'absence', 'absence_perc', 'linear', 'linear_perc', 'train_size'))\n",
    "        else:\n",
    "            eval_model = pd.DataFrame([[simulations+1, loss,accuracy,absencecorrect,abscor_percent,lincorrect,lincor_percent, size_of_training]], \n",
    "                                      columns=('run', 'loss', 'accuracy', 'absence', 'absence_perc', 'linear', 'linear_perc', 'train_size'))\n",
    "            evaluation = evaluation.append(eval_model, ignore_index = True)\n",
    "            \n",
    "    #print('time after simulation of size', size_of_training, 'is', datetime.now().time())   \n",
    "    #evaluation.to_csv('data/linear/l_sim_acc_' + str(size_of_training) + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate hierarchical train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size_of_training in range(100,1100,100):\n",
    "    \n",
    "    for simulations in range(100):\n",
    "        K.clear_session()\n",
    "        print('simulation number: ', simulations+1)\n",
    "        hiercorrect = 0\n",
    "        absencecorrect = 0\n",
    "        countabsent = 0\n",
    "\n",
    "        h_input_data_train, h_output_data_train, h_input_data_test, h_output_data_test = gen_hier(train_size=size_of_training)\n",
    "\n",
    "        # define class weights\n",
    "        y_int = [y.argmax() for y in h_output_data_train]\n",
    "        class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "        class_weightz = {0: 0, 1: 0, 2: class_weights[0], 3: class_weights[1], 4: class_weights[2], \n",
    "                 5: class_weights[3], 6: class_weights[4], 7: class_weights[5], 8: class_weights[6]}\n",
    "    \n",
    "        vec_in = Input(shape=(4, 57), dtype='float32', name='vec_in')\n",
    "        lstm = LSTM(100, return_sequences=False, name='lstm1')(vec_in)\n",
    "        target_pos = Dense(9, name='target_pos', activation='softmax')(lstm)\n",
    "        model = Model(inputs=vec_in,outputs=target_pos)\n",
    "        model.summary()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(h_input_data_train,h_output_data_train, steps_per_epoch=100, epochs=50,verbose=1,class_weight=class_weights)\n",
    "\n",
    "        eval_model = model.evaluate(x = h_input_data_test, y = h_output_data_test, verbose = 1) \n",
    "        loss = eval_model[0]\n",
    "        accuracy = eval_model[1]\n",
    "\n",
    "        predictions = model.predict(h_input_data_test)\n",
    "        for testtrials in range(len(predictions)):\n",
    "            index_prediction = list(predictions[testtrials]).index(max(predictions[testtrials]))+1\n",
    "            index_answer = list(h_output_data_test[testtrials]).index(max(h_output_data_test[testtrials]))+1\n",
    "\n",
    "            if index_answer == 9:\n",
    "                countabsent += 1\n",
    "\n",
    "            if index_prediction == index_answer:\n",
    "                if index_answer == 9:\n",
    "                    absencecorrect += 1\n",
    "                else:\n",
    "                    hiercorrect += 1\n",
    "                    \n",
    "        abscor_percent = absencecorrect/countabsent*100\n",
    "        hiercor_percent = hiercorrect/(100-countabsent)*100\n",
    "\n",
    "        if simulations == 0:\n",
    "            evaluation = pd.DataFrame([[simulations+1, loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent, size_of_training]], \n",
    "                                       columns=('run', 'loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc', 'train_size'))\n",
    "        else:\n",
    "            eval_model = pd.DataFrame([[simulations+1, loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent, size_of_training]], \n",
    "                                      columns=('run', 'loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc', 'train_size'))\n",
    "            evaluation = evaluation.append(eval_model, ignore_index = True)\n",
    "            \n",
    "    #print('time after simulation of size', size_of_training, 'is', datetime.now().time())\n",
    "    #evaluation.to_csv('data/hierarchical/h_sim_acc_' + str(size_of_training) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate ambiguous train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size_of_training in range(100,200,100):\n",
    "    \n",
    "    for simulations in range(100):\n",
    "        K.clear_session()\n",
    "        print('simulation number: ', simulations+1)\n",
    "        hiercorrect = 0\n",
    "        absencecorrect = 0\n",
    "        lincorrect = 0\n",
    "        countabsent = 0\n",
    "       \n",
    "        # generate divergent test data\n",
    "        a_input_data_test, a_output_hier_data_test, a_output_linear_data_test = gen_amb(train_gen=False)\n",
    "\n",
    "        # generate ambiguoust training data\n",
    "        a_input_data_train, a_output_data_train = gen_amb(train_gen=True, train_size=size_of_training)\n",
    "\n",
    "        # define class weights\n",
    "        y_int = [y.argmax() for y in a_output_data_train]\n",
    "        class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "        class_weights = {0: 0, 1: class_weights[0], 2: class_weights[1], 3: class_weights[2], \n",
    "             4: class_weights[3], 5: class_weights[4], 6: class_weights[5], 7: 0, 8: class_weights[6]}\n",
    "\n",
    "        vec_in = Input(shape=(4, 57), dtype='float32', name='vec_in')\n",
    "        lstm = LSTM(100, return_sequences=False, name='lstm')(vec_in)\n",
    "        target_pos = Dense(9, name='target_pos', activation='softmax')(lstm)\n",
    "        model = Model(inputs=vec_in,outputs=target_pos)\n",
    "        model.summary()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(a_input_data_train,a_output_data_train, steps_per_epoch=100, epochs=50,verbose=1,class_weight=class_weights)\n",
    "\n",
    "        # evaluate on hierarchical answers \n",
    "        eval_model_hier = model.evaluate(x = a_input_data_test, y = a_output_hier_data_test, verbose = 1)\n",
    "        losshier = eval_model_hier[0]\n",
    "        accuracyhier = eval_model_hier[1]\n",
    "\n",
    "        # evaluate on linear answers\n",
    "        eval_model_lin = model.evaluate(x = a_input_data_test, y = a_output_linear_data_test, verbose = 1)\n",
    "        losslin = eval_model_lin[0]\n",
    "        accuracylin = eval_model_lin[1]\n",
    "\n",
    "        predictions = model.predict(a_input_data_test_100)\n",
    "\n",
    "        for testtrials in range(len(predictions)):\n",
    "            index_prediction = list(predictions[testtrials]).index(max(predictions[testtrials]))+1\n",
    "            index_answerhier = list(a_output_hier_data_test[testtrials]).index(max(a_output_hier_data_test[testtrials]))+1\n",
    "            index_answerlin = list(a_output_linear_data_test[testtrials]).index(max(a_output_linear_data_test[testtrials]))+1\n",
    "\n",
    "            if index_answerhier == 9:\n",
    "                countabsent += 1\n",
    "\n",
    "            if index_prediction == index_answerhier:\n",
    "                if index_answerhier == 9:\n",
    "                    absencecorrect += 1\n",
    "                else:\n",
    "                    hiercorrect += 1\n",
    "            elif index_prediction == index_answerlin:\n",
    "                lincorrect += 1\n",
    "\n",
    "        abscor_percent = absencecorrect/countabsent*100\n",
    "        hiercor_percent = hiercorrect/(100-countabsent)*100\n",
    "        lincor_percent = lincorrect/(100-countabsent)*100\n",
    "        \n",
    "        if simulations == 0:\n",
    "            evaluation = pd.DataFrame([[losshier,accuracyhier,losslin,accuracylin,absencecorrect,abscor_percent,hiercorrect,\n",
    "                                        hiercor_percent,lincorrect,lincor_percent]], \n",
    "                                       columns=('losshier','accuracyhier','losslin','accuracylin','absence', 'absence_perc', \n",
    "                                                'hierarchical', 'hierarchical_perc', 'linear', 'linear_perc'))\n",
    "        else:\n",
    "            eval_model = pd.DataFrame([[losshier,accuracyhier,losslin,accuracylin,absencecorrect,abscor_percent,hiercorrect,\n",
    "                                        hiercor_percent,lincorrect,lincor_percent]], \n",
    "                                       columns=('losshier','accuracyhier','losslin','accuracylin','absence', 'absence_perc', \n",
    "                                                'hierarchical', 'hierarchical_perc', 'linear', 'linear_perc'))\n",
    "            evaluation = evaluation.append(eval_model, ignore_index = True)\n",
    "\n",
    "    #print('time after simulation is', datetime.now().time())\n",
    "    #evaluation.to_csv('data/ambiguous/a_sim_acc_' + str(size_of_training) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate mixed train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size_of_training in range(100,200,100):\n",
    "    ratios = [[0,100]]#[[100,0],[90,10],[80,20],[70,30],[60,40],[50,50],[40,60],[30,70],[20,80],[10,90],[0,100]]\n",
    "    \n",
    "    for ratio in range(len(ratios)):\n",
    "        size_of_training = 100\n",
    "        rat_mult = size_of_training/100 # to multiply training ratio\n",
    "\n",
    "        for simulations in range(1):\n",
    "            K.clear_session()\n",
    "            print('simulation number: ', simulations+1)\n",
    "            hiercorrect = 0\n",
    "            absencecorrect = 0\n",
    "            lincorrect = 0\n",
    "            countabsent = 0\n",
    "\n",
    "            # generate divergent test data\n",
    "            a_input_data_test, a_output_hier_data_test, a_output_linear_data_test = gen_mixed(train_gen=False)\n",
    "\n",
    "            enough_classes = False\n",
    "            while enough_classes == False:\n",
    "                # generate ambiguoust training data\n",
    "                a_input_data_train, a_output_data_train = gen_mixed(train_gen=True, ratio_amb = int(rat_mult*ratios[ratio][0]), \n",
    "                                                                          ratio_hier = int(rat_mult*ratios[ratio][1]))\n",
    "\n",
    "                #define class weights\n",
    "                y_int = [y.argmax() for y in a_output_data_train]\n",
    "                class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "\n",
    "                if ratios[ratio][0] == 100 :\n",
    "                    if len(class_weights) == 7:\n",
    "                        enough_classes = True\n",
    "                elif ratios[ratio][0] == 0 :\n",
    "                    if len(class_weights) == 7:\n",
    "                        enough_classes = True\n",
    "                else:\n",
    "                    if len(class_weights) == 8:\n",
    "                        enough_classes = True\n",
    "\n",
    "            # if all data are ambiguous, 1 and 8 are not possible outputs\n",
    "            if ratios[ratio][0] == 100:\n",
    "                class_weights = {0: 0, 1: class_weights[0], 2: class_weights[1], 3: class_weights[2], \n",
    "                             4: class_weights[3], 5: class_weights[4], 6: class_weights[5], 7: 0, 8: class_weights[6]}\n",
    "\n",
    "            # if all data are hierarchical, 1 and 2 are not possible outputs \n",
    "            elif ratios[ratio][0] == 0:\n",
    "                class_weights = {0: 0, 1: 0, 2: class_weights[0], 3: class_weights[1], 4: class_weights[2], \n",
    "                             5: class_weights[3], 6: class_weights[4], 7: class_weights[5], \n",
    "                             8: class_weights[6]}\n",
    "\n",
    "            # if the data are mixed, only 1 is not a possible output\n",
    "            else:\n",
    "                class_weights = {0: 0, 1: class_weights[0], 2: class_weights[1], 3: class_weights[2], \n",
    "                             4: class_weights[3], 5: class_weights[4], 6: class_weights[5], \n",
    "                             7: class_weights[6], 8: class_weights[7]}\n",
    "\n",
    "            vec_in = Input(shape=(4, 57), dtype='float32', name='vec_in')\n",
    "            lstm = LSTM(100, return_sequences=False, name='lstm')(vec_in)\n",
    "            target_pos = Dense(9, name='target_pos', activation = 'softmax')(lstm)\n",
    "            model = Model(inputs=vec_in,outputs=target_pos)\n",
    "            model.summary()\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            model.fit(a_input_data_train,a_output_data_train, steps_per_epoch=100, epochs=50,verbose=1, class_weight = class_weights)\n",
    "\n",
    "            # evaluate on hierarchical answers \n",
    "            eval_model_hier = model.evaluate(x = a_input_data_test, y = a_output_hier_data_test, verbose = 1)\n",
    "            losshier = eval_model_hier[0]\n",
    "            accuracyhier = eval_model_hier[1]\n",
    "\n",
    "            # evaluate on linear answers\n",
    "            eval_model_lin = model.evaluate(x = a_input_data_test, y = a_output_linear_data_test, verbose = 1)\n",
    "            losslin = eval_model_lin[0]\n",
    "            accuracylin = eval_model_lin[1]\n",
    "\n",
    "            predictions = model.predict(a_input_data_test)\n",
    "\n",
    "            for testtrials in range(len(predictions)):\n",
    "                index_prediction = list(predictions[testtrials]).index(max(predictions[testtrials]))+1\n",
    "                index_answerhier = list(a_output_hier_data_test[testtrials]).index(max(a_output_hier_data_test[testtrials]))+1\n",
    "                index_answerlin = list(a_output_linear_data_test[testtrials]).index(max(a_output_linear_data_test[testtrials]))+1\n",
    "\n",
    "                if index_answerhier == 9:\n",
    "                    countabsent += 1\n",
    "\n",
    "                if index_prediction == index_answerhier:\n",
    "                    if index_answerhier == 9:\n",
    "                        absencecorrect += 1\n",
    "                    else:\n",
    "                        hiercorrect += 1\n",
    "                elif index_prediction == index_answerlin:\n",
    "                    lincorrect += 1\n",
    "\n",
    "            abscor_percent = absencecorrect/countabsent*100\n",
    "            hiercor_percent = hiercorrect/(100-countabsent)*100\n",
    "            lincor_percent = lincorrect/(100-countabsent)*100\n",
    "            \n",
    "            if simulations == 0:\n",
    "                evaluation = pd.DataFrame([[losshier,accuracyhier,losslin,accuracylin,absencecorrect,abscor_percent,hiercorrect,\n",
    "                                            hiercor_percent,lincorrect,lincor_percent]], \n",
    "                                           columns=('losshier','accuracyhier','losslin','accuracylin','absence', 'absence_perc', \n",
    "                                                    'hierarchical', 'hierarchical_perc', 'linear', 'linear_perc'))\n",
    "            else:\n",
    "                eval_model = pd.DataFrame([[losshier,accuracyhier,losslin,accuracylin,absencecorrect,abscor_percent,hiercorrect,\n",
    "                                            hiercor_percent,lincorrect,lincor_percent]], \n",
    "                                           columns=('losshier','accuracyhier','losslin','accuracylin','absence', 'absence_perc', \n",
    "                                                    'hierarchical', 'hierarchical_perc', 'linear', 'linear_perc'))\n",
    "                evaluation = evaluation.append(eval_model, ignore_index = True)\n",
    "\n",
    "        #print('time after simulation is', datetime.now().time())\n",
    "        #evaluation.to_csv('data/mixed/ah_sim_acc_' + str(size_of_training) + 'train_' + str(ratios[ratio][0]) + '_' + str(ratios[ratio][1]) + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
