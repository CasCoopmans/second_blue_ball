{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, dot, multiply, Lambda\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from random import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from datetime import datetime\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator_generalization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate generalization test with one-hot input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for simulations in range(100):\n",
    "    K.clear_session()\n",
    "    print('simulation number: ', simulations+1)\n",
    "    hiercorrect = 0\n",
    "    absencecorrect = 0\n",
    "    countabsent = 0\n",
    "    \n",
    "    ### generate data for generalization test: gen_type = 'int' or 'ext'\n",
    "    input_train, output_train, input_test, output_test = gen_hier_onehot(train_size=500, gen_type='ext', random_training=False)\n",
    "\n",
    "    # define class weights\n",
    "    y_int = [y.argmax() for y in output_train]\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "\n",
    "    ### if training is not random\n",
    "    class_weights = {0: 0, 1: 0, 2: class_weights[0], 3: class_weights[1], 4: class_weights[2], \n",
    "                 5: class_weights[3], 6: class_weights[4], 7: class_weights[5], 8: class_weights[6]}\n",
    "\n",
    "    ### if training is random\n",
    "    '''\n",
    "    class_weights = {0: 0, 1: 0, 2: 0, 3: class_weights[0], 4: class_weights[1], 5: class_weights[2], \n",
    "                 6: class_weights[3], 7: class_weights[4], 8: class_weights[5]}\n",
    "    '''\n",
    "    \n",
    "    vec_in = Input(shape=(4, 74), dtype='float32', name='vec_in')\n",
    "    lstm = LSTM(100, return_sequences=False, name='lstm1')(vec_in)\n",
    "    target_pos = Dense(9, name='target_pos', activation='softmax')(lstm)\n",
    "    model = Model(inputs=vec_in,outputs=target_pos)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(input_train,output_train, steps_per_epoch=100, epochs=50,verbose=1,class_weight=class_weights)\n",
    "    \n",
    "    eval_model = model.evaluate(x = input_test, y = output_test, verbose = 1) \n",
    "    loss = eval_model[0]\n",
    "    accuracy = eval_model[1]\n",
    "    \n",
    "    predictions = model.predict(input_test)\n",
    "    for testtrials in range(len(predictions)):\n",
    "        index_prediction = list(predictions[testtrials]).index(max(predictions[testtrials]))+1\n",
    "        index_answer = list(output_test[testtrials]).index(max(output_test[testtrials]))+1\n",
    "        \n",
    "        if index_answer == 9:\n",
    "            countabsent += 1\n",
    "            \n",
    "        if index_prediction == index_answer:\n",
    "            if index_answer == 9:\n",
    "                absencecorrect += 1\n",
    "            else:\n",
    "                hiercorrect += 1\n",
    "                \n",
    "    abscor_percent = absencecorrect/countabsent*100\n",
    "    hiercor_percent = hiercorrect/(100-countabsent)*100    \n",
    "    \n",
    "    if simulations == 0:\n",
    "        evaluation = pd.DataFrame([[loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent]], \n",
    "                                   columns=('loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc'))\n",
    "    else:\n",
    "        eval_model = pd.DataFrame([[loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent]], \n",
    "                                  columns=('loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc'))\n",
    "        evaluation = evaluation.append(eval_model, ignore_index = True)\n",
    "\n",
    "    #evaluation.to_csv('data/generalization/extrapolation/h_gen1_sim_acc_500thirdred_onehot.csv', index=False)\n",
    "    #evaluation.to_csv('data/generalization/interpolation/h_gen2_sim_acc_500thirdred_onehot.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate generalization test with full word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for simulations in range(100):\n",
    "    K.clear_session()\n",
    "    print('simulation number: ', simulations+1)\n",
    "    hiercorrect = 0\n",
    "    absencecorrect = 0\n",
    "    countabsent = 0\n",
    "\n",
    "    ### generate data for generalization test: gen_type = 'int' or 'ext'\n",
    "    input_train, output_train, input_test, output_test = gen_hier_embful(train_size=500, gen_type='ext')\n",
    "\n",
    "    # define class weights\n",
    "    y_int = [y.argmax() for y in output_train]\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "    class_weights = {0: 0, 1: 0, 2: class_weights[0], 3: class_weights[1], 4: class_weights[2], \n",
    "                 5: class_weights[3], 6: class_weights[4], 7: class_weights[5], 8: class_weights[6]}\n",
    "    \n",
    "    vec_in = Input(shape=(4, 364), dtype='float32', name='vec_in')\n",
    "    lstm = LSTM(100, return_sequences=False, name='lstm1')(vec_in)\n",
    "    target_pos = Dense(9, name='target_pos', activation='softmax')(lstm)\n",
    "    model = Model(inputs=vec_in,outputs=target_pos)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(input_train,output_train, steps_per_epoch=100, epochs=50,verbose=1,class_weight=class_weights)\n",
    "    \n",
    "    eval_model = model.evaluate(x = input_test, y = output_test, verbose = 1) \n",
    "    loss = eval_model[0]\n",
    "    accuracy = eval_model[1]\n",
    "    \n",
    "    predictions = model.predict(input_test)\n",
    "    for testtrials in range(len(predictions)):\n",
    "        index_prediction = list(predictions[testtrials]).index(max(predictions[testtrials]))+1\n",
    "        index_answer = list(output_test[testtrials]).index(max(output_test[testtrials]))+1\n",
    "        \n",
    "        if index_answer == 9:\n",
    "            countabsent += 1\n",
    "            \n",
    "        if index_prediction == index_answer:\n",
    "            if index_answer == 9:\n",
    "                absencecorrect += 1\n",
    "            else:\n",
    "                hiercorrect += 1\n",
    "                \n",
    "    abscor_percent = absencecorrect/countabsent*100\n",
    "    hiercor_percent = hiercorrect/(100-countabsent)*100  \n",
    "    \n",
    "    if simulations == 0:\n",
    "        evaluation = pd.DataFrame([[loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent]], \n",
    "                                   columns=('loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc'))\n",
    "    else:\n",
    "        eval_model = pd.DataFrame([[loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent]], \n",
    "                                  columns=('loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc'))\n",
    "        evaluation = evaluation.append(eval_model, ignore_index = True)\n",
    "\n",
    "    #evaluation.to_csv('data/generalization/extrapolation/h_gen1_sim_acc_500thirdred_embful.csv', index=False)\n",
    "    #evaluation.to_csv('data/generalization/interpolation/h_gen2_sim_acc_500thirdred_embful.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate generalization test with dimensionality-reduced word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for simulations in range(100):\n",
    "    K.clear_session()\n",
    "    print('simulation number: ', simulations+1)\n",
    "    hiercorrect = 0\n",
    "    absencecorrect = 0\n",
    "    countabsent = 0\n",
    "\n",
    "    ### generate data for generalization test: gen_type = 'int' or 'ext'\n",
    "    input_train, output_train, input_test, output_test = gen_hier_embred(train_size=500, gen_type='ext')\n",
    "        \n",
    "    # define class weights\n",
    "    y_int = [y.argmax() for y in output_train]\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "    class_weights = {0: 0, 1: 0, 2: class_weights[0], 3: class_weights[1], 4: class_weights[2], \n",
    "                 5: class_weights[3], 6: class_weights[4], 7: class_weights[5], 8: class_weights[6]}\n",
    "    \n",
    "    vec_in = Input(shape=(4, 74), dtype='float32', name='vec_in')\n",
    "    lstm = LSTM(100, return_sequences=False, name='lstm1')(vec_in)\n",
    "    target_pos = Dense(9, name='target_pos', activation='softmax')(lstm)\n",
    "    model = Model(inputs=vec_in,outputs=target_pos)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(input_train,output_train, steps_per_epoch=100, epochs=50,verbose=1,class_weight=class_weights)\n",
    "    \n",
    "    eval_model = model.evaluate(x = input_test, y = output_test, verbose = 1) \n",
    "    loss = eval_model[0]\n",
    "    accuracy = eval_model[1]\n",
    "    \n",
    "    predictions = model.predict(input_test)\n",
    "    for testtrials in range(len(predictions)):\n",
    "        index_prediction = list(predictions[testtrials]).index(max(predictions[testtrials]))+1\n",
    "        index_answer = list(output_test[testtrials]).index(max(output_test[testtrials]))+1\n",
    "        \n",
    "        if index_answer == 9:\n",
    "            countabsent += 1\n",
    "            \n",
    "        if index_prediction == index_answer:\n",
    "            if index_answer == 9:\n",
    "                absencecorrect += 1\n",
    "            else:\n",
    "                hiercorrect += 1\n",
    "                \n",
    "    abscor_percent = absencecorrect/countabsent*100\n",
    "    hiercor_percent = hiercorrect/(100-countabsent)*100 \n",
    "    \n",
    "    if simulations == 0:\n",
    "        evaluation = pd.DataFrame([[loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent]], \n",
    "                                   columns=('loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc'))\n",
    "    else:\n",
    "        eval_model = pd.DataFrame([[loss,accuracy,absencecorrect,abscor_percent,hiercorrect,hiercor_percent]], \n",
    "                                  columns=('loss', 'accuracy', 'absence', 'absence_perc', 'hierarchical', 'hierarchical_perc'))\n",
    "        evaluation = evaluation.append(eval_model, ignore_index = True)\n",
    "\n",
    "    #evaluation.to_csv('data/generalization/extrapolation/h_gen1_sim_acc_500thirdred_embred.csv', index=False)\n",
    "    #evaluation.to_csv('data/generalization/interpolation/h_gen2_sim_acc_500thirdred_embred.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
