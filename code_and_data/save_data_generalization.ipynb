{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, dot, multiply, Lambda\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from random import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from datetime import datetime\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator_generalization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, output_train, input_test, output_test = gen_hier_onehot(train_size = 100, gen_type = 'ext', random_training = False)\n",
    "#input_train, output_train, input_test, output_test = gen_hier_embful(train_size = 500, gen_type = 'ext')\n",
    "#input_train, output_train, input_test, output_test = gen_hier_embred(train_size = 500, gen_type = 'ext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_int = [y.argmax() for y in output_train]\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_int), y_int)\n",
    "\n",
    "# for regular training\n",
    "class_weights = {0: 0, 1: 0, 2: class_weights[0], 3: class_weights[1], 4: class_weights[2], \n",
    "             5: class_weights[3], 6: class_weights[4], 7: class_weights[5], 8: class_weights[6]}\n",
    "\n",
    "# for training on pseudorandom data\n",
    "#class_weights = {0: 0, 1: 0, 2: 0, 3: class_weights[0], 4: class_weights[1], 5: class_weights[2], \n",
    "#             6: class_weights[3], 7: class_weights[4], 8: class_weights[5]}\n",
    "\n",
    "#vec_in = Input(shape=(4, 74), dtype='float32', name='vec_in') # one-hot\n",
    "vec_in = Input(shape=(4, 364), dtype='float32', name='vec_in') # full embeddings\n",
    "#vec_in = Input(shape=(4, 74), dtype='float32', name='vec_in') # reduced embeddings\n",
    "lstm = LSTM(100, return_sequences=False, name='lstm1')(vec_in)\n",
    "target_pos = Dense(9, name='target_pos', activation='softmax')(lstm)\n",
    "model = Model(inputs=vec_in,outputs=target_pos)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(input_train,output_train, steps_per_epoch=100, epochs=50,verbose=1,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions on test set (one-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_test)\n",
    "train_size = 500\n",
    "\n",
    "for runs in range(len(input_test)):\n",
    "\n",
    "    df_pic = pd.DataFrame([[['..'],['..'],['..'],\n",
    "                            ['...', '...',],['...', '...',],['...', '...',],['...', '...',],\n",
    "                            ['...', '...',],['...', '...',],['...', '...',],['...', '...',],\n",
    "                            ['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],\n",
    "                            ['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],\n",
    "                            ['..'],['..'],['..'],['..'],['..'],['..']]], \n",
    "                            columns= ['ordinal', 'color', 'shape', \n",
    "                                      '1', '2', '3', '4', '5', '6', '7', '8','o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9',\n",
    "                                      'p1', 'p2', 'p3', 'p4','p5', 'p6', 'p7', 'p8','p9', 'index', 'max', 'correctness','answer_item', 'train_size'])\n",
    "    \n",
    "    #gets the index of the highest value\n",
    "    i_answer = list(predictions[runs]).index(max(predictions[runs]))+1 # index of max value\n",
    "    p_answer = max(predictions[runs]) # max value\n",
    "    \n",
    "    df_pic['index'][0] = i_answer\n",
    "    df_pic['max'][0] = p_answer\n",
    "     \n",
    "    # load input and split into phrase and picture\n",
    "    ordnum = input_test[runs][0]\n",
    "    colnum = input_test[runs][1]\n",
    "    shapenum = input_test[runs][2]\n",
    "    \n",
    "    ordnum = list(ordnum)\n",
    "    colnum = list(colnum)\n",
    "    shapenum = list(shapenum)\n",
    "    \n",
    "    ## the phrase\n",
    "    \n",
    "    # ordinal of target phrase\n",
    "    if ordnum[:6] == [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]:\n",
    "        ordinal = 'seventh'\n",
    "        lin_ans = 1\n",
    "    elif ordnum[:6] == [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]:\n",
    "        ordinal = 'second'\n",
    "        lin_ans = 2\n",
    "    elif ordnum[:6] == [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]:\n",
    "        ordinal = 'third'\n",
    "        lin_ans = 3\n",
    "    elif ordnum[:6] == [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]:\n",
    "        ordinal = 'fourth'\n",
    "        lin_ans = 4\n",
    "    elif ordnum[:6] == [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]:\n",
    "        ordinal = 'fifth'\n",
    "        lin_ans = 5\n",
    "    elif ordnum[:6] == [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]:\n",
    "        ordinal = 'sixth'\n",
    "        lin_ans = 5\n",
    "    else:\n",
    "        ordinal = 'ordinal?'\n",
    "\n",
    "    #check what kind of answer the model produced\n",
    "    if i_answer == list(output_test[runs]).index(max(output_test[runs]))+1:\n",
    "        if output_test[runs][8] == 1:\n",
    "            synt_ans = 'absence correct'\n",
    "        else:\n",
    "            synt_ans = 'hierarchical'\n",
    "    else:\n",
    "        synt_ans = 'error'\n",
    " \n",
    "    # color of target phrase\n",
    "    if colnum[:9] == [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]:\n",
    "        color = 'blue'\n",
    "    elif colnum[:9] == [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]:\n",
    "        color = 'green'\n",
    "    elif colnum[:9] == [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]:\n",
    "        color = 'red'\n",
    "    \n",
    "    # shape of target phrase\n",
    "    if shapenum[:10] == [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]:\n",
    "        shape = 'ball'\n",
    "    else:\n",
    "        shape = 'shape?'\n",
    "    \n",
    "    ## the picture\n",
    "\n",
    "    # load input and split into phrase and picture\n",
    "    picnum = input_test[runs][3]\n",
    "    picnum = picnum[10:]\n",
    "\n",
    "    smallrun = 0\n",
    "    for elements in range(0,64,8):\n",
    "        smallrun += 1\n",
    "\n",
    "        colrange1 = elements\n",
    "        colrange2 = elements+4\n",
    "        \n",
    "        shaperange1 = elements+4\n",
    "        shaperange2 = elements+8\n",
    "\n",
    "        colnum = list(picnum[colrange1:colrange2])\n",
    "        if colnum == [0.25, 0.0, 0.0, 0.0]:\n",
    "            color_pic = 'blue'\n",
    "        elif colnum == [0.0, 0.25, 0.0, 0.0]:\n",
    "            color_pic = 'green'\n",
    "        elif colnum == [0.0, 0.0, 0.25, 0.0]:\n",
    "            color_pic = 'red'\n",
    "\n",
    "        shapenum = list(picnum[shaperange1:shaperange2])\n",
    "        if shapenum == [0.0, 0.0, 0.0, 0.25]:\n",
    "            shape_pic = 'ball'\n",
    "        else:\n",
    "            shape_pic = 'shape?'    \n",
    "\n",
    "        props = [color_pic, shape_pic]\n",
    "\n",
    "        df_pic[str(smallrun)][0] = props\n",
    "    \n",
    "    df_pic['ordinal'][0] = ordinal\n",
    "    df_pic['color'][0] = color\n",
    "    df_pic['shape'][0] = shape\n",
    "    df_pic['o1'][0] = output_test[runs][0]    \n",
    "    df_pic['o2'][0] = output_test[runs][1] \n",
    "    df_pic['o3'][0] = output_test[runs][2] \n",
    "    df_pic['o4'][0] = output_test[runs][3] \n",
    "    df_pic['o5'][0] = output_test[runs][4] \n",
    "    df_pic['o6'][0] = output_test[runs][5] \n",
    "    df_pic['o7'][0] = output_test[runs][6] \n",
    "    df_pic['o8'][0] = output_test[runs][7] \n",
    "    df_pic['o9'][0] = output_test[runs][8] \n",
    "    df_pic['p1'][0] = predictions[runs][0]    \n",
    "    df_pic['p2'][0] = predictions[runs][1] \n",
    "    df_pic['p3'][0] = predictions[runs][2] \n",
    "    df_pic['p4'][0] = predictions[runs][3] \n",
    "    df_pic['p5'][0] = predictions[runs][4] \n",
    "    df_pic['p6'][0] = predictions[runs][5] \n",
    "    df_pic['p7'][0] = predictions[runs][6] \n",
    "    df_pic['p8'][0] = predictions[runs][7]\n",
    "    df_pic['p9'][0] = predictions[runs][8]\n",
    "    df_pic['correctness'][0] = synt_ans\n",
    "    if i_answer < 9:\n",
    "        df_pic['answer_item'][0] = df_pic[str(i_answer)][0] \n",
    "    else:\n",
    "        df_pic['answer_item'][0] = 'target absent'\n",
    "    df_pic['train_size'][0] = train_size \n",
    "   \n",
    "    if runs == 0:\n",
    "        phrase_and_pic = pd.DataFrame(df_pic, columns= ['ordinal', 'color', 'shape', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "                                                          'o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9',\n",
    "                                                          'p1', 'p2', 'p3', 'p4','p5', 'p6', 'p7', 'p8', 'p9','index', 'max', 'correctness', 'answer_item', 'train_size'])\n",
    "    else:\n",
    "        phrase_and_pic = phrase_and_pic.append(df_pic, ignore_index=True)\n",
    "    \n",
    "    \n",
    "print(phrase_and_pic)\n",
    "#phrase_and_pic.to_csv('data/generalization/extrapolation/h_gen1_pred_500thirdred_onehot.csv', index=False)\n",
    "#phrase_and_pic.to_csv('data/generalization/interpolation/h_gen2_pred_500thirdred_onehot.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions on test set (full embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_test)\n",
    "train_size = 500\n",
    "\n",
    "# load dimensionality-reduced embeddings\n",
    "myembeddings = pd.read_csv('word2vec/embeddings.csv', header = 0)\n",
    "myembeddings = myembeddings['embedding']\n",
    "# convert the embeddings from list to string of floats\n",
    "second = np.array(np.matrix(myembeddings[0])).ravel()\n",
    "third = np.array(np.matrix(myembeddings[1])).ravel()\n",
    "fourth = np.array(np.matrix(myembeddings[2])).ravel()\n",
    "fifth = np.array(np.matrix(myembeddings[3])).ravel()\n",
    "sixth = np.array(np.matrix(myembeddings[4])).ravel()\n",
    "seventh = np.array(np.matrix(myembeddings[5])).ravel()\n",
    "blue = np.array(np.matrix(myembeddings[6])).ravel()\n",
    "green = np.array(np.matrix(myembeddings[7])).ravel()\n",
    "red = np.array(np.matrix(myembeddings[8])).ravel()\n",
    "ball = np.array(np.matrix(myembeddings[9])).ravel()\n",
    "\n",
    "for runs in range(len(input_test)):\n",
    "\n",
    "    df_pic = pd.DataFrame([[['..'],['..'],['..'],\n",
    "                            ['...', '...',],['...', '...',],['...', '...',],['...', '...',],\n",
    "                            ['...', '...',],['...', '...',],['...', '...',],['...', '...',],\n",
    "                            ['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],\n",
    "                            ['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],\n",
    "                            ['..'],['..'],['..'],['..'],['..']]], \n",
    "                            columns= ['ordinal', 'color', 'shape', \n",
    "                                      '1', '2', '3', '4', '5', '6', '7', '8','o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9',\n",
    "                                      'p1', 'p2', 'p3', 'p4','p5', 'p6', 'p7', 'p8', 'index', 'max', 'correctness','answer_item', 'train_size'])\n",
    "    \n",
    "    #gets the index of the highest value\n",
    "    i_answer = list(predictions[runs]).index(max(predictions[runs]))+1 # index of max value\n",
    "    p_answer = max(predictions[runs]) # max value\n",
    "    \n",
    "    df_pic['index'][0] = i_answer\n",
    "    df_pic['max'][0] = p_answer\n",
    "     \n",
    "    # load input and split into phrase and picture\n",
    "    ordnum = input_test[runs][0]\n",
    "    colnum = input_test[runs][1]\n",
    "    shapenum = input_test[runs][2]\n",
    "    \n",
    "    ordnum = list(ordnum)\n",
    "    colnum = list(colnum)\n",
    "    shapenum = list(shapenum)\n",
    "    \n",
    "    ## the phrase\n",
    "    \n",
    "    # save what the ordinal was\n",
    "    if (ordnum[:300] == second).all() == True:\n",
    "        ordinal = 'second'\n",
    "        lin_ans = 2\n",
    "    elif (ordnum[:300] == third).all() == True:\n",
    "        ordinal = 'third'\n",
    "        lin_ans = 3\n",
    "    elif (ordnum[:300] == fourth).all() == True:\n",
    "        ordinal = 'fourth'\n",
    "        lin_ans = 4\n",
    "    elif (ordnum[:300] == fifth).all() == True:\n",
    "        ordinal = 'fifth'\n",
    "        lin_ans = 5\n",
    "    elif (ordnum[:300] == sixth).all() == True:\n",
    "        ordinal = 'sixth'\n",
    "        lin_ans = 6\n",
    "    elif (ordnum[:300] == seventh).all() == True:\n",
    "        ordinal = 'seventh'\n",
    "        lin_ans = 7\n",
    "    else:\n",
    "        ordinal = 'ordinal?'\n",
    "\n",
    "    #check what kind of answer the model produced\n",
    "    if i_answer == list(output_test[runs]).index(max(output_test[runs]))+1:\n",
    "        if output_test[runs][8] == 0:\n",
    "            synt_ans = 'hierarchical'\n",
    "        else:\n",
    "            synt_ans = 'absence correct'\n",
    "    else:\n",
    "        synt_ans = 'error'\n",
    "     \n",
    "    # color of target phrase\n",
    "    if (colnum[:300] == blue).all() == True:\n",
    "        color = 'blue'\n",
    "    elif (colnum[:300] == green).all() == True:\n",
    "        color = 'green'\n",
    "    elif (colnum[:300] == red).all() == True:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'color?'\n",
    " \n",
    "    # shape of target phrase\n",
    "    if (shapenum[:300] == ball).all() == True:\n",
    "        shape = 'ball'\n",
    "    else:\n",
    "        shape = 'shape?'\n",
    "    \n",
    "    ## the picture\n",
    "\n",
    "    # load input and split into phrase and picture\n",
    "    picnum = input_test[runs][3]\n",
    "    picnum = picnum[300:]\n",
    "\n",
    "    smallrun = 0\n",
    "    for elements in range(0,64,8):\n",
    "        smallrun += 1\n",
    "\n",
    "        colrange1 = elements\n",
    "        colrange2 = elements+4\n",
    "        \n",
    "        shaperange1 = elements+4\n",
    "        shaperange2 = elements+8\n",
    "        \n",
    "        colnum = list(picnum[colrange1:colrange2])\n",
    "        if colnum == [0.25, 0.0, 0.0, 0.0]:\n",
    "            color_pic = 'blue'\n",
    "        elif colnum == [0.0, 0.25, 0.0, 0.0]:\n",
    "            color_pic = 'green'\n",
    "        elif colnum == [0.0, 0.0, 0.25, 0.0]:\n",
    "            color_pic = 'red'\n",
    "\n",
    "        shapenum = list(picnum[shaperange1:shaperange2])\n",
    "        if shapenum == [0.0, 0.0, 0.0, 0.25]:\n",
    "            shape_pic = 'ball'\n",
    "        else:\n",
    "            shape_pic = 'shape?'    \n",
    "\n",
    "        props = [color_pic, shape_pic]\n",
    "\n",
    "        df_pic[str(smallrun)][0] = props\n",
    "    \n",
    "    df_pic['ordinal'][0] = ordinal\n",
    "    df_pic['color'][0] = color\n",
    "    df_pic['shape'][0] = shape\n",
    "    df_pic['o1'][0] = output_test[runs][0]    \n",
    "    df_pic['o2'][0] = output_test[runs][1] \n",
    "    df_pic['o3'][0] = output_test[runs][2] \n",
    "    df_pic['o4'][0] = output_test[runs][3] \n",
    "    df_pic['o5'][0] = output_test[runs][4] \n",
    "    df_pic['o6'][0] = output_test[runs][5] \n",
    "    df_pic['o7'][0] = output_test[runs][6] \n",
    "    df_pic['o8'][0] = output_test[runs][7] \n",
    "    df_pic['o9'][0] = output_test[runs][8] \n",
    "    df_pic['p1'][0] = predictions[runs][0]    \n",
    "    df_pic['p2'][0] = predictions[runs][1] \n",
    "    df_pic['p3'][0] = predictions[runs][2] \n",
    "    df_pic['p4'][0] = predictions[runs][3] \n",
    "    df_pic['p5'][0] = predictions[runs][4] \n",
    "    df_pic['p6'][0] = predictions[runs][5] \n",
    "    df_pic['p7'][0] = predictions[runs][6] \n",
    "    df_pic['p8'][0] = predictions[runs][7]\n",
    "    df_pic['correctness'][0] = synt_ans\n",
    "    if i_answer < 9:\n",
    "        df_pic['answer_item'][0] = df_pic[str(i_answer)][0] \n",
    "    else:\n",
    "        df_pic['answer_item'][0] = 'target absent'\n",
    "    df_pic['train_size'][0] = train_size \n",
    "   \n",
    "    if runs == 0:\n",
    "        phrase_and_pic = pd.DataFrame(df_pic, columns= ['ordinal', 'color', 'shape', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "                                                          'o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9',\n",
    "                                                          'p1', 'p2', 'p3', 'p4','p5', 'p6', 'p7', 'p8', 'index', 'max', 'correctness', 'answer_item', 'train_size'])\n",
    "    else:\n",
    "        phrase_and_pic = phrase_and_pic.append(df_pic, ignore_index=True)\n",
    "    \n",
    "    \n",
    "print(phrase_and_pic)\n",
    "\n",
    "#phrase_and_pic.to_csv('data/generalization/extrapolation/h_gen1_pred_500thirdred_embful.csv', index=False)\n",
    "#phrase_and_pic.to_csv('data/generalization/interpolation/h_gen2_pred_500thirdred_embful.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions on test set (reduced embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_test)\n",
    "train_size = 500\n",
    "\n",
    "# words in word2vec representation\n",
    "myembeddings = pd.read_csv('word2vec/reduced_embeddings.csv', header = 0)\n",
    "myembeddings = myembeddings['embedding']\n",
    "# convert the embeddings from list to string of floats\n",
    "second = np.array(np.matrix(myembeddings[0])).ravel()\n",
    "third = np.array(np.matrix(myembeddings[1])).ravel()\n",
    "fourth = np.array(np.matrix(myembeddings[2])).ravel()\n",
    "fifth = np.array(np.matrix(myembeddings[3])).ravel()\n",
    "sixth = np.array(np.matrix(myembeddings[4])).ravel()\n",
    "seventh = np.array(np.matrix(myembeddings[5])).ravel()\n",
    "blue = np.array(np.matrix(myembeddings[6])).ravel()\n",
    "green = np.array(np.matrix(myembeddings[7])).ravel()\n",
    "red = np.array(np.matrix(myembeddings[8])).ravel()\n",
    "ball = np.array(np.matrix(myembeddings[9])).ravel()\n",
    "\n",
    "for runs in range(len(input_test)):\n",
    "\n",
    "    df_pic = pd.DataFrame([[['..'],['..'],['..'],\n",
    "                            ['...', '...',],['...', '...',],['...', '...',],['...', '...',],\n",
    "                            ['...', '...',],['...', '...',],['...', '...',],['...', '...',],\n",
    "                            ['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],\n",
    "                            ['..'],['..'],['..'],['..'],['..'],['..'],['..'],['..'],\n",
    "                            ['..'],['..'],['..'],['..'],['..']]], \n",
    "                            columns= ['ordinal', 'color', 'shape', \n",
    "                                      '1', '2', '3', '4', '5', '6', '7', '8','o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9',\n",
    "                                      'p1', 'p2', 'p3', 'p4','p5', 'p6', 'p7', 'p8', 'index', 'max', 'correctness','answer_item', 'train_size'])\n",
    "    \n",
    "    #gets the index of the highest value\n",
    "    i_answer = list(predictions[runs]).index(max(predictions[runs]))+1 # index of max value\n",
    "    p_answer = max(predictions[runs]) # max value\n",
    "    \n",
    "    df_pic['index'][0] = i_answer\n",
    "    df_pic['max'][0] = p_answer\n",
    "     \n",
    "    # load input and split into phrase and picture\n",
    "    ordnum = input_test[runs][0]\n",
    "    colnum = input_test[runs][1]\n",
    "    shapenum = input_test[runs][2]\n",
    "    \n",
    "    ordnum = list(ordnum)\n",
    "    colnum = list(colnum)\n",
    "    shapenum = list(shapenum)\n",
    "    \n",
    "    ## the phrase\n",
    "    \n",
    "    # save what the ordinal was\n",
    "    if (ordnum[:10] == second).all() == True:\n",
    "        ordinal = 'second'\n",
    "        lin_ans = 2\n",
    "    elif (ordnum[:10] == third).all() == True:\n",
    "        ordinal = 'third'\n",
    "        lin_ans = 3\n",
    "    elif (ordnum[:10] == fourth).all() == True:\n",
    "        ordinal = 'fourth'\n",
    "        lin_ans = 4\n",
    "    elif (ordnum[:10] == fifth).all() == True:\n",
    "        ordinal = 'fifth'\n",
    "        lin_ans = 5\n",
    "    elif (ordnum[:10] == sixth).all() == True:\n",
    "        ordinal = 'sixth'\n",
    "        lin_ans = 6\n",
    "    elif (ordnum[:10] == seventh).all() == True:\n",
    "        ordinal = 'seventh'\n",
    "        lin_ans = 7\n",
    "    else:\n",
    "        ordinal = 'ordinal?'\n",
    "\n",
    "    #check what kind of answer the model produced\n",
    "    if i_answer == list(output_test[runs]).index(max(output_test[runs]))+1:\n",
    "        if output_test[runs][8] == 0:\n",
    "            synt_ans = 'hierarchical'\n",
    "        else:\n",
    "            synt_ans = 'absence correct'\n",
    "    else:\n",
    "        synt_ans = 'error'\n",
    "     \n",
    "    # color of target phrase\n",
    "    if (colnum[:10] == blue).all() == True:\n",
    "        color = 'blue'\n",
    "    elif (colnum[:10] == green).all() == True:\n",
    "        color = 'green'\n",
    "    elif (colnum[:10] == red).all() == True:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'color?'\n",
    " \n",
    "    # shape of target phrase\n",
    "    if (shapenum[:10] == ball).all() == True:\n",
    "        shape = 'ball'\n",
    "    else:\n",
    "        shape = 'shape?'\n",
    "    \n",
    "    ## the picture\n",
    "\n",
    "    # load input and split into phrase and picture\n",
    "    picnum = input_test[runs][3]\n",
    "    picnum = picnum[10:]\n",
    "\n",
    "    smallrun = 0\n",
    "    for elements in range(0,64,8):\n",
    "        smallrun += 1\n",
    "\n",
    "        colrange1 = elements\n",
    "        colrange2 = elements+4\n",
    "        \n",
    "        shaperange1 = elements+4\n",
    "        shaperange2 = elements+8\n",
    "        \n",
    "        colnum = list(picnum[colrange1:colrange2])\n",
    "        if colnum == [0.25, 0.0, 0.0, 0.0]:\n",
    "            color_pic = 'blue'\n",
    "        elif colnum == [0.0, 0.25, 0.0, 0.0]:\n",
    "            color_pic = 'green'\n",
    "        elif colnum == [0.0, 0.0, 0.25, 0.0]:\n",
    "            color_pic = 'red'\n",
    "\n",
    "        shapenum = list(picnum[shaperange1:shaperange2])\n",
    "        if shapenum == [0.0, 0.0, 0.0, 0.25]:\n",
    "            shape_pic = 'ball'\n",
    "        else:\n",
    "            shape_pic = 'shape?'    \n",
    "\n",
    "        props = [color_pic, shape_pic]\n",
    "\n",
    "        df_pic[str(smallrun)][0] = props\n",
    "    \n",
    "    df_pic['ordinal'][0] = ordinal\n",
    "    df_pic['color'][0] = color\n",
    "    df_pic['shape'][0] = shape\n",
    "    df_pic['o1'][0] = output_test[runs][0]    \n",
    "    df_pic['o2'][0] = output_test[runs][1] \n",
    "    df_pic['o3'][0] = output_test[runs][2] \n",
    "    df_pic['o4'][0] = output_test[runs][3] \n",
    "    df_pic['o5'][0] = output_test[runs][4] \n",
    "    df_pic['o6'][0] = output_test[runs][5] \n",
    "    df_pic['o7'][0] = output_test[runs][6] \n",
    "    df_pic['o8'][0] = output_test[runs][7] \n",
    "    df_pic['o9'][0] = output_test[runs][8] \n",
    "    df_pic['p1'][0] = predictions[runs][0]    \n",
    "    df_pic['p2'][0] = predictions[runs][1] \n",
    "    df_pic['p3'][0] = predictions[runs][2] \n",
    "    df_pic['p4'][0] = predictions[runs][3] \n",
    "    df_pic['p5'][0] = predictions[runs][4] \n",
    "    df_pic['p6'][0] = predictions[runs][5] \n",
    "    df_pic['p7'][0] = predictions[runs][6] \n",
    "    df_pic['p8'][0] = predictions[runs][7]\n",
    "    df_pic['correctness'][0] = synt_ans\n",
    "    if i_answer < 9:\n",
    "        df_pic['answer_item'][0] = df_pic[str(i_answer)][0] \n",
    "    else:\n",
    "        df_pic['answer_item'][0] = 'target absent'\n",
    "    df_pic['train_size'][0] = train_size \n",
    "   \n",
    "    if runs == 0:\n",
    "        phrase_and_pic = pd.DataFrame(df_pic, columns= ['ordinal', 'color', 'shape', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "                                                          'o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9',\n",
    "                                                          'p1', 'p2', 'p3', 'p4','p5', 'p6', 'p7', 'p8', 'index', 'max', 'correctness', 'answer_item', 'train_size'])\n",
    "    else:\n",
    "        phrase_and_pic = phrase_and_pic.append(df_pic, ignore_index=True)\n",
    "    \n",
    "    \n",
    "print(phrase_and_pic)\n",
    "\n",
    "#phrase_and_pic.to_csv('data/generalization/extrapolation/h_gen1_pred_500thirdred_embred.csv', index=False)\n",
    "#phrase_and_pic.to_csv('data/generalization/interpolation/h_gen2_pred_500thirdred_embred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
